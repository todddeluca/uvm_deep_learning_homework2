{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Homework 2\n",
    "\n",
    "By: Todd DeLuca\n",
    "\n",
    "Class: UVM CSYS 395 Deep Learning, Spring 2018, taught by Prof. Safwan Wshah.\n",
    "\n",
    "This homework explores the training and use of character-to-character sequence models.  All the code for the project can be found at https://github.com/todddeluca/uvm_deep_learning_homework2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data and Representation\n",
    "\n",
    "- Select you training dataset. Keep in mind, first of all, that your dataset has to be big\n",
    "  in order to learn the structure, typically RNNs have been trained on highly diverse\n",
    "  texts such as novels, Eminem lyrics, programming code, etc. (so be creative here!)\n",
    "  Easy option, Gutenberg Books is a source of free books where you may download full\n",
    "  novels in a .txt format.\n",
    "- You need to use a character-level representation for this model. Convert the chosen\n",
    "  training set to the extended ASCII of 256 characters, read characters one at a time\n",
    "  and convert it into a one-hot-encoding. Each character will map to a vector of ones\n",
    "  and zeros, where the one indicates which of the characters is present. Your RNN will\n",
    "  read in binary vector of length-256."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "\n",
    "The following datasets were used in this project:\n",
    "\n",
    "- First Names\n",
    "  - 7944 names, split between 2943 male names and 5001 female names.\n",
    "  - Source: http://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/areas/nlp/corpora/names/\n",
    "- Jokes\n",
    "  - 10019 jokes of questionable taste and humor, from the `wocka.json` file.\n",
    "  - https://github.com/taivop/joke-dataset\n",
    "- Pride and Prejudice by Jane Austen\n",
    "  - 4671 sentences, 121567 words, and 682302 characters.\n",
    "  - Source: The Gutenberg Project at http://www.gutenberg.org/ebooks/1342\n",
    "  \n",
    "Datasets were downloaded in the notebook 'download'.  Nothing fancy here.  Just downloading and storing files to a data directory, either automatically or by hand.\n",
    "  \n",
    "### Preprocessing\n",
    "\n",
    "The extended ASCII encoding, ISO-8859-1, aka ISO Latin 1, was chosen to encode dataset characters as integers in the range [0, 255].  In the preprocessing code, text was converted, character-by-character, to integers and then one-hot encoded as input to the deep learning models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Training\n",
    "\n",
    "Train your recurrent neural network using the dataset you created in Part1. You are free to\n",
    "choose learning parameters (sequence length, learning rate, stopping criteria, etc.), to make\n",
    "it easy for you, you can use build in function from deep learning toolkits to implement and\n",
    "train RNN architectures. Complete the following task:\n",
    "\n",
    "- Report your training procedure. Plot the training loss vs. # of training epochs.\n",
    "- During training, choose 5 breaking points (for example, you train the network for\n",
    "  100 epochs and you choose the end of epoch 20,40,60,80,100) and show how well\n",
    "  your network learns through time. You can do it by feeding in the network a chunk of\n",
    "  your training text and show what is the output of the network. Report your result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Experiments\n",
    "\n",
    "Experiment with different Network Structures. Discuss your findings if you change these\n",
    "parameters:\n",
    "\n",
    "- Number of hidden units. Try doubling and halving your number of hidden units. plot\n",
    "  the training loss vs. the # of training epochs and show your text sampling results.\n",
    "- Sequence length. Try doubling and halving your length of sequence that feeds into\n",
    "  the network. plot the training loss vs. the #of training epochs and show your text\n",
    "  sampling results.\n",
    "- Replace your RNN with LSTM and GRU. plot the training loss vs. the #of training\n",
    "  epochs and show your text sampling results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
